| [arxiv](https://arxiv.org/abs/1511.05493) | ICLR 2016 |

![](Pasted%20image%2020240613144510.png)

where $Ïƒ(i(h_v^{(T)}, x_v))$ acts as a soft attention mechanism that decides which nodes are relevant to the current graph-level task. $i$ and $j$ are neural networks that take the concatenation of $h_v^{(T)}$ and $x_v$ as input and outputs real-valued vectors. The $tanh$ functions can also be replaced with the identity.